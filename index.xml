<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>ATAP</title><link>https://www.atap.edu.au/</link><description>The Australian Text Analytics Platform is an open source environment that provides researchers with tools and training for analysing, processing, and exploring text.</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><managingEditor>info@atap.edu.au (Australian Text Analytics Project)</managingEditor><webMaster>info@atap.edu.au (Australian Text Analytics Project)</webMaster><lastBuildDate>Tue, 28 Mar 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://www.atap.edu.au/index.xml" rel="self" type="application/rss+xml"/><item><title>Introducing the ATAP Quotation Tool: Extracting quotes and entities from newspaper articles</title><link>https://www.atap.edu.au/posts/quotation-tool/</link><pubDate>Tue, 28 Mar 2023 00:00:00 +0000</pubDate><author>Kelvin Lee</author><guid>https://www.atap.edu.au/posts/quotation-tool/</guid><description><![CDATA[<p>The ATAP Quotation Tool is a Jupyter notebook containing code that was adapted and developed (with permission) from the <a href="https://github.com/sfu-discourse-lab/GenderGapTracker" target="_blank" rel="noopener noreffer ">GenderGapTracker</a> by the Sydney Informatics Hub (<a href="https://www.sydney.edu.au/research/facilities/sydney-informatics-hub.html" target="_blank" rel="noopener noreffer ">SIH</a>) in collaboration with the <a href="https://sydneycorpuslab.com/" target="_blank" rel="noopener noreffer ">Sydney Corpus Lab</a> as part of the Australian Text Analytics Platform (<a href="https://www.atap.edu.au" target="_blank" rel="noopener noreffer ">ATAP</a>) project.</p>
<p>The quotation tool is designed to identify and extract quoted content from newspaper texts. Since the tool uses a combination of syntactic and heuristic rules to extract quotes, it is able to identify quotes whether they are marked by quoting or projecting verbs (e.g. <em>said</em>) or not.</p>
<p>The tool can also use <a href="https://en.wikipedia.org/wiki/Named-entity_recognition" target="_blank" rel="noopener noreffer ">Named-Entity Recognition</a> to identify and classify the sources of these quotes and the entities within these quotes (as people, organisations, etc.). This is useful for answering a number of questions such as those related to representation of voices/sources (e.g. Who is cited the most/least? Who is not cited at all?) and those related to quoted content (e.g. What kind of information is sourced from others?).</p>
<p>The tool can also identify the verbs that are used to cite quotations (e.g. <em>say, tell, add, claim, admit</em>). This will be particularly useful to those interested in the variation of reporting verbs.</p>
<p>Once the tool has processed the files, it will display the first few identified and extracted quotes (and entities) in a table. An example of this preview table is shown in Table 1 below, which displays the identified quote along with information such as the speaker and their entity type, the entity name and type of the entities identified within the quote and the quoting/projecting verb (if there is one). The type of quote is described on the basis of the various components of the quote construction (Q = quotation mark, S = speaker, V = verb, C = content) and their linear order.</p>
<data id="id-1" data-raw></data>
<p>The tool allows you to save and download the complete table of results as an Excel worksheet (.xslx format) for further analysis.</p>
<p>It is also possible to preview all the identified quotes and entities in individual files. In this preview (see Figure 1 below), identified quotes and entities are presented in bold face and labelled accordingly (e.g. as quote/speaker or as a specific entity type such as PERSON, NORP, GPE – see legend to Figure 2 for abbreviations). You can download the visualisation such as the one shown in Figure 1 as an html file.</p>
<data id="id-2" data-raw></data>
<p>The tool also allows you to visualise the top named entities identified in the quotes and/or the top entity types among identified speakers as bar graphs – an example is shown in Figure 2.</p>
<data id="id-3" data-raw></data>
<p>You can choose to visualise the top entities for the whole corpus/dataset or individual files within the corpus/dataset. Other options for the visualisation include whether to display the entity names and/or types, and the number of top entities to display (i.e. in multiples of five). You can also choose to save the graphs (based on the set parameters) as jpg files.</p>
<p>The tool is available on <a href="https://github.com/Australian-Text-Analytics-Platform/quotation-tool" target="_blank" rel="noopener noreffer ">GitHub</a> where you can launch the tool on Jupyter Notebook via Binder. That instance of Binder uses CILogon authentication, and you can access it by signing in with your (Australian) institutional login credentials or Google/Microsoft/Outlook account. If you have access to software that supports Jupyter Notebooks, you can also download the notebook to use locally (i.e. without Internet connection) on your own computer.</p>
<p>If you have any questions, feedback, and/or comments about the tool, you can contact the SIH at <a href="mailto:sih.info@sydney.edu.au" rel="">sih.info@sydney.edu.au</a>.</p>
<h3 id="acknowledgments">Acknowledgments</h3>
<p>This Jupyter notebook and relevant python scripts were developed by the Sydney Informatics Hub (SIH) in collaboration with the Sydney Corpus Lab under the <a href="https://doi.org/10.47486/PL074" target="_blank" rel="noopener noreffer ">Australian Text Analytics Platform program</a> and the <a href="https://doi.org/10.47486/HIR001" target="_blank" rel="noopener noreffer ">HASS Research Data Commons and Indigenous Research Capability Program</a>. These projects received investment from the Australian Research Data Commons (<a href="https://www.ardc.edu.au" target="_blank" rel="noopener noreffer ">ARDC</a>), which is funded by the National Collaborative Research Infrastructure Strategy (<a href="https://www.education.gov.au/ncris" target="_blank" rel="noopener noreffer ">NCRIS</a>).</p>
<h3 id="how-to-cite-the-notebook">How to cite the notebook:</h3>
<p>If you are using this notebook in your research, please include the following statement or an appropriate variation thereof:</p>
<p><em>This study has utilised a notebook/notebooks developed for the Australian Text Analytics Platform (<a href="https://www.atap.edu.au" target="_blank" rel="noopener noreffer ">https://www.atap.edu.au</a>) available at (<a href="https://github.com/Australian-Text-Analytics-Platform/quotation-tool%29" target="_blank" rel="noopener noreffer ">https://github.com/Australian-Text-Analytics-Platform/quotation-tool)</a>.</em></p>
<p>In addition, please inform ATAP (<a href="mailto:info@atap.edu.au" rel="">info@atap.edu.au</a>) of publications and grant applications deriving from the use of any ATAP notebooks in order to support continued funding and development of the platform.</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
]]></description></item><item><title>Introducing the Document Similarity Tool: A new tool for corpus building</title><link>https://www.atap.edu.au/posts/similarity-tool/</link><pubDate>Tue, 07 Mar 2023 00:00:00 +0000</pubDate><author>Kelvin Lee</author><guid>https://www.atap.edu.au/posts/similarity-tool/</guid><description><![CDATA[<p>The Document Similarity tool is a Jupyter notebook containing code that was developed by the Sydney Informatics Hub (<a href="https://www.sydney.edu.au/research/facilities/sydney-informatics-hub.html" target="_blank" rel="noopener noreffer ">SIH</a>) in collaboration with the <a href="https://sydneycorpuslab.com/" target="_blank" rel="noopener noreffer ">Sydney Corpus Lab</a> as part of the Australian Text Analytics Platform (<a href="https://www.atap.edu.au" target="_blank" rel="noopener noreffer ">ATAP</a>) project. It uses <a href="https://ekzhu.com/datasketch/minhash.html" target="_blank" rel="noopener noreffer ">MinHash</a> to estimate the <a href="https://en.wikipedia.org/wiki/Jaccard_index" target="_blank" rel="noopener noreffer ">Jaccard similarity</a> between sets of documents. This tool is helpful in cleaning data files in a dataset or corpus. This is particularly useful to those who collect media texts (e.g. of newspaper articles, tweets) where fully or partially duplicated texts are common occurrences.</p>
<p>The tool is designed to compare every pair of texts in a dataset or corpus and produce similarity scores. Based on a similarity cut-off that has been specified (either the default cut-off parameters or ones that you set yourself), the tool retrieves pairs of texts where the similarity score exceeds the pre-determined cut-off. The result of this analysis is presented as a table containing a list of similar documents (in pairs) found by the tool – an example is shown in Table 1 below. Based on this analysis, the tool makes recommendations about which text within each similar pair should be kept or removed – as shown in the ‘status1’ and ‘status2’ columns in Table 1.</p>
<data id="id-1" data-raw></data>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p>The tool allows you to view each pair of similar documents (by specifying the row index you wish to analyse; see Figure 1 below), analyse them, and update the action/recommendation (i.e. ‘keep’ and ‘remove’). You can then download the non-duplicated texts (those labelled as <em>keep</em>) or the duplicated ones (those labelled as <em>remove</em>) into a zip archive of text (.txt) files.</p>
<data id="id-2" data-raw></data>
<p>Additionally, the tool allows you to visualise the Jaccard similarity scores as a histogram (Figure 2). The histogram shows the Jaccard similarity scores for every pair of texts/documents in the corpus, and how many similar documents are found at those Jaccard similarity score ranges across the corpus. This is useful for estimating the extent of duplicated content in a corpus.</p>
<data id="id-3" data-raw></data>
<p>Another, optional, visualisation shows the Jaccard similarity scores between specific pairs of texts/documents as a heatmap. This can be useful for identifying the texts that are most similar to each other, but works best with small numbers of texts. This optional feature of the tool could be used to compare the texts produced by different speakers/authors in a dataset.</p>
<p>The tool is available on <a href="https://github.com/Australian-Text-Analytics-Platform/document-similarity/" target="_blank" rel="noopener noreffer ">GitHub</a> where you can launch the tool on Jupyter Notebook via Binder. That instance of Binder uses CILogon authentication, and you can access it by signing in with your (Australian) institutional login credentials or Google/Microsoft/Outlook account. If you have access to software that supports Jupyter Notebooks, you can also download the notebook to use locally (i.e. without Internet connection) on your own computer.</p>
<p>If you have any questions, feedback, and/or comments about the tool, you can contact the SIH at <a href="mailto:sih.info@sydney.edu.au" rel="">sih.info@sydney.edu.au</a>.</p>
<h3 id="acknowledgments">Acknowledgments</h3>
<p>This Jupyter notebook and relevant python scripts were developed by the Sydney Informatics Hub (SIH) in collaboration with the Sydney Corpus Lab under the <a href="https://doi.org/10.47486/PL074" target="_blank" rel="noopener noreffer ">Australian Text Analytics Platform program</a> and the <a href="https://doi.org/10.47486/HIR001" target="_blank" rel="noopener noreffer ">HASS Research Data Commons and Indigenous Research Capability Program</a>. These projects received investment from the Australian Research Data Commons (<a href="https://www.ardc.edu.au" target="_blank" rel="noopener noreffer ">ARDC</a>), which is funded by the National Collaborative Research Infrastructure Strategy (<a href="https://www.education.gov.au/ncris" target="_blank" rel="noopener noreffer ">NCRIS</a>).</p>
<p>The notebook incorporates MinHash, which is introduced by Andrei Z. Broder in this <a href="https://cs.brown.edu/courses/cs253/papers/nearduplicate.pdf" target="_blank" rel="noopener noreffer ">paper</a>. Details can be found <a href="https://ekzhu.com/datasketch/minhash.html" target="_blank" rel="noopener noreffer ">here</a>.</p>
<h3 id="how-to-cite-the-notebook">How to cite the notebook:</h3>
<p>If you are using this notebook in your research, please include the following statement or an appropriate variation thereof:</p>
<p><em>This study has utilised a notebook/notebooks developed for the Australian Text Analytics Platform (<a href="https://www.atap.edu.au" target="_blank" rel="noopener noreffer ">https://www.atap.edu.au</a>) available at (<a href="https://github.com/Australian-Text-Analytics-Platform/document-similarity/%29" target="_blank" rel="noopener noreffer ">https://github.com/Australian-Text-Analytics-Platform/document-similarity/)</a>.</em></p>
<p>In addition, please inform ATAP (<a href="mailto:info@atap.edu.au" rel="">info@atap.edu.au</a>) of publications and grant applications deriving from the use of any ATAP notebooks in order to support continued funding and development of the platform.</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
]]></description></item><item><title>Discursis</title><link>https://www.atap.edu.au/posts/discursis/</link><pubDate>Thu, 10 Nov 2022 00:00:00 +0000</pubDate><author>Simon Musgrave</author><guid>https://www.atap.edu.au/posts/discursis/</guid><description><![CDATA[<p>Discursis is communication analytics technology that allows a user to analyse text based communication data, such as conversations, web forums and training scenarios. It uses natural language processing (NLP) algorithms to automatically process transcribed text to highlight participant interactions around specific topics and over the time-course of the conversation. Discursis can assist practitioners in understanding the structure, information content, and inter-speaker relationships that are present within input data. Discursis also provides quantitative measures of key metrics, such as topic introduction, topic consistency, and topic novelty.</p>
<p>The NLP algorithms are used to construct a matrix of concept similarity scores between the sections into which a text has been divided. In the typical use case for this tool, that of a discourse with several speakers, those sections will be speaker turns and the similarity matrix provides information about the extent to which any pair of turns share concepts. This information, along with the sequential nature of the interaction, makes it possible to track topics which are maintained, or dropped, or dropped and then picked up again. It is also possible to examine the extent to which speakers are sharing concepts. These possibilities have been used in analysing various kinds of interactions, including medical consultations (see references below).</p>
<p>Discursis also has tools for visualising the analysis, and you can see an example of this below. The data on which these graphics are based is a debate between Kevin Rudd and Tony Abbott held at the National Press Club on 11 August 2013. Figure 1 shows a visualisation of the whole debate.</p>
<p><data id="id-1" data-raw></data>
Figure 2 zooms in on a section of the interaction. The boxes on the diagonal represent the speaker turns, and you can see in Figure 2 that hovering the cursor over a box causes the text of that turn to be visible.
<data id="id-2" data-raw></data></p>
<p>The boxes back in the matrix represent the conceptual similarity between each pair of turns. A heavily populated column means that the topics in a turn were also in many following turns and a heavily populated row means that a turn shared topics with many preceding turns. Selecting a point of intersection in the matrix displays a similarity score for the turns, and the text of both turns is displayed below the main graphic (not shown here).</p>
<p><a href="https://itee.uq.edu.au/project/discursis" target="_blank" rel="noopener noreffer ">Discursis</a> was developed by <a href="https://www.qut.edu.au/about/our-people/academic-profiles/daniel.angus" target="_blank" rel="noopener noreffer ">Dan Angus</a>, <a href="https://itee.uq.edu.au/profile/2444/janet-wiles" target="_blank" rel="noopener noreffer ">Janet Wiles</a> and Andrew Smith and has been reworked as an open source tool by staff of <a href="https://www.sydney.edu.au/research/facilities/sydney-informatics-hub.html" target="_blank" rel="noopener noreffer ">Sydney Informatics Hub</a>. A version of the tool running in a Jupyter notebook is available in this <a href="https://github.com/Australian-Text-Analytics-Platform/discursis" target="_blank" rel="noopener noreffer ">Github repository</a>.</p>
<h4 id="references">References</h4>
<data id="id-3" data-raw></data>
<h3 id="acknowledgments">Acknowledgments</h3>
<p>This Jupyter notebook and relevant python scripts were developed by the Sydney Informatics Hub (SIH) in collaboration with the Sydney Corpus Lab under the <a href="https://doi.org/10.47486/PL074" target="_blank" rel="noopener noreffer ">Australian Text Analytics Platform program</a> and the <a href="https://doi.org/10.47486/HIR001" target="_blank" rel="noopener noreffer ">HASS Research Data Commons and Indigenous Research Capability Program</a>. These projects received investment from the Australian Research Data Commons (<a href="https://www.ardc.edu.au" target="_blank" rel="noopener noreffer ">ARDC</a>), which is funded by the National Collaborative Research Infrastructure Strategy (<a href="https://www.education.gov.au/ncris" target="_blank" rel="noopener noreffer ">NCRIS</a>).</p>
<h3 id="how-to-cite-the-notebook">How to cite the notebook:</h3>
<p>If you are using this notebook in your research, please include the following statement or an appropriate variation thereof:</p>
<p><em>This study has utilised a notebook/notebooks developed for the Australian Text Analytics Platform (<a href="https://www.atap.edu.au" target="_blank" rel="noopener noreffer ">https://www.atap.edu.au</a>) available at (<a href="https://github.com/Australian-Text-Analytics-Platform/discursis%29" target="_blank" rel="noopener noreffer ">https://github.com/Australian-Text-Analytics-Platform/discursis)</a>.</em></p>
<p>In addition, please inform ATAP (<a href="mailto:info@atap.edu.au" rel="">info@atap.edu.au</a>) of publications and grant applications deriving from the use of any ATAP notebooks in order to support continued funding and development of the platform.</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
]]></description></item><item><title>ATAP Architecture Introduction</title><link>https://www.atap.edu.au/posts/atap-arch-preso/</link><pubDate>Fri, 16 Sep 2022 00:00:00 +0000</pubDate><author>Peter Sefton</author><guid>https://www.atap.edu.au/posts/atap-arch-preso/</guid><description><![CDATA[<p><a href="/posts/atap-arch-preso/HASS_RDC_Technical_Advisory_Group_ATAP%20intro.pdf" rel="">PDF version</a></p>
<p>This presentation was given By Moises Sacal Bonequi, Ben Foley and Peter Sefton to the HASS RDC and Indigenous Research Capability Program
Technical Advisory Group Meeting on 2022-09-02.</p>
<data id="id-1" data-raw></data>
<p>The Language Data Commons of Australia (LDaCA) and the Australian Text Analytics Platform (ATAP) are establishing a scalable and flexible language data and analytics commons. These projects will be part of the Humanities and Social Sciences Research Data Commons (HASS RDC).</p>
<p>The Data Commons will focus on preservation and discovery of distributed multi-modal language data collections under a variety of governance frameworks. This will include access control that reflects ethical constraints and intellectual property rights, including those of Aboriginal and Torres Strait Islander, migrant and Pacific communities.</p>
<p>This presentation builds on an <a href="https://www.ldaca.edu.au/posts/rdc-tech-meeting" target="_blank" rel="noopener noreffer ">overview of the LDaCA and ATAP architecture</a> from 2022-02-11. This time we will zoom in on the Text Analytics side and show progress on linking active workspaces for an analysis with access-controlled data repositories, creating a <a href="https://www.nature.com/articles/sdata201618" target="_blank" rel="noopener noreffer ">FAIR</a>-ready platform. Parts of this presentation are recycled from the previous one.</p>
<p><data id="id-2" data-raw></data>
For this Research Data Commons work we are using the Arkisto Platform (introduced <a href="http://ptsefton.com/2020/11/23/Arkisto/index.html" target="_blank" rel="noopener noreffer ">at eResearch 2020</a>).</p>
<p>Arkisto aims to ensure the long term preservation of data independently of code and services, recognizing the ephemeral nature of software and platforms. We know that sustaining software platforms can be hard and aim to make sure that important data assets are not locked up in database or hard-coded logic of some hard-to-maintain application.</p>
<p><data id="id-3" data-raw></data>
The above diagram takes a big-picture view of research data management in the context of <em>doing</em> research. It makes a distinction between managed repository storage and the places where work is done - “workspaces”. Workspaces are where researchers collect, analyse and describe data. Examples include the most basic of research IT services, file storage, as well as analytical tools such as Jupyter notebooks (the backbone of ATAP - the text analytics platform). Other examples of workspaces include code repositories such as GitHub or GitLab (a slightly different sense of the word repository), survey tools, electronic (lab) notebooks and bespoke code written for particular research programmes. These workspaces are essential research systems but usually are not set up for long term management of data.
The cycle in the centre of this diagram shows an idealised research practice where data are collected and described and deposited into a repository frequently. Data are made findable and accessible as soon as possible and can be “re-collected” for use and re-use.</p>
<p>For data to be re-usable by humans and machines (such as ATAP notebook code that consumes datasets in a predictable way) it must be well described. The ATAP and LDaCA approach to this is to use the Research Object Crate (RO-Crate) specification. RO-Crate is essentially a guide to using a number of standards to describe both data and re-runnable software such as workflows or notebooks.</p>
<p><data id="id-4" data-raw></data>
This rather messy slide represents the overall high-level architecture for the LDaCA Research Data Commons. There will be an analytical workbench (left of the diagram) which is the basis of the Australian Text Analytics (ATAP) project. This will focus on notebook-style programming using one of the emerging Jupyter notebook platforms in that space. Our engagement lead, Dr Simon Musgrave sees the ATAP work as primarily an educational enterprise encouraging researchers to adopt new research practices, which will be underpinned by services built on the Arkisto standards, allowing for rigorous, re-runnable research.</p>
<p><data id="id-5" data-raw></data>
This diagram is a much simpler view zooming in on the core infrastructure components that we have built so far. We are starting with bulk ingest of existing collections and will add one-by-one deposit of individual items after that.</p>
<p>This shows the OCFL repository at the bottom, with a Data &amp; Access API that mediates access. This API understands the RO-Crate format and in particular its use of the Portland Common Data Model to structure data. The API also enforces access control to objects. Every repository object has a license setting out the terms of use and re-use for its data, which will reflect the way the data were collected. Information about copyright and privacy laws, and whether participants have signed agreements and ethics approvals, are all relevant here. Each license will correspond to a group of people who have agreed to and/or been selected by a data custodian. We are in negotiations with the <a href="https://aaf.edu.au/" target="_blank" rel="noopener noreffer ">Australian Access Federation (AAF)</a> to use their <a href="https://www.cilogon.org/" target="_blank" rel="noopener noreffer ">CILogon</a> service for this authorization step and for authentication of users across a wide variety of services including the AAF itself, Google, Microsoft and GitHub.</p>
<p>There’s also an access portal which will be based on a full-text index (at this stage we’re using ElasticSearch) which is designed to help people find data they might be interested in using. This follows current conventions for browse/search interfaces which we’re familiar with from shopping sites. You can search for text and/or drill down using <em>facets</em> (which are called aggregations in Elastic-land), for example, “which language am I in interested in” or “do I want [ ] Spoken or [ ] Written material”?</p>
<p><data id="id-6" data-raw></data>
This diagram shows some of the main components in the ATAP ecosystem of services.</p>
<p>A website (where you are reading this) will guide users to data in repository services (green, bottom left) where they can see data and tools together. Here, the user can choose code to run, which will then be instantiated by the BinderHub service (pink, bottom right) in the “workspaces”.</p>
<p>The website will also aid in discovery of training and events.</p>
<p><data id="id-7" data-raw></data>
This silent screen recording shows Moises Sacal Bonequi navigating through the first two of many data collections in the <a href="https://data.atap.edu.au/" target="_blank" rel="noopener noreffer ">ATAP data repository</a>, looking at discovery information that describes the collections and their context. Each of the collections are linked to Jupyter notebooks that can consume data from the notebooks. When Moises clicks on one of these, he can preview it in the data portal, and launch it into a fresh virtual computing instance via the ATAP BinderHub workspace running on the <a href="https://ardc.edu.au/services/nectar-research-cloud/" target="_blank" rel="noopener noreffer ">ARDC Nectar Research Cloud</a>.</p>
<p>The recording also shows a couple of Jupyter notebooks that operate on the two data collections in the repository.</p>
<ol>
<li>
<p>The <a href="https://github.com/Australian-Text-Analytics-Platform/cooee/blob/main/cooee.ipynb" target="_blank" rel="noopener noreffer ">COOEE notebook</a>, developed by Ben Foley the Applications and Training lead at ATAP, is a bare-bones demonstration of how to explore the collection, look at files etc.</p>
</li>
<li>
<p>The <a href="https://github.com/Australian-Text-Analytics-Platform/farms-to-freeways/blob/main/farms-to-freeways.ipynb" target="_blank" rel="noopener noreffer ">Farms to Freeways notebook</a> was developed by one of the data scientists who was working with us at UQ, Mel Mistica, along with our tech team. This notebook uses the API to get the metadata for a social history collection containing transcribed interviews with women in Western Sydney. The notebook shows how a data scientist might explore what’s in a collection, such as the age distribution of the participants, and start analysing the content in the collection.</p>
</li>
</ol>
<p>Next steps:</p>
<ul>
<li>add more data, more notebooks and training material</li>
<li>extend functionality of the BinderHub workshop for wider range of notebooks</li>
</ul>
]]></description></item><item><title>Textbooks, tutorials and tool chests: different ways to learn from notebooks - Part 1</title><link>https://www.atap.edu.au/posts/notebooks-1/</link><pubDate>Wed, 27 Jul 2022 16:20:35 +1000</pubDate><author>Joel Nothman</author><guid>https://www.atap.edu.au/posts/notebooks-1/</guid><description><![CDATA[<h5 id="this-work-was-supported-by-the-sydney-informatics-hubhttpswwwsydneyeduauresearchfacilitiessydney-informatics-hubhtml-a-core-research-facility-of-the-university-of-sydney">This work was supported by the <a href="https://www.sydney.edu.au/research/facilities/sydney-informatics-hub.html" target="_blank" rel="noopener noreffer ">Sydney Informatics Hub</a>, a Core Research Facility of the University of Sydney</h5>
<p>One objective of the Australian Text Analytics Platform is to provide a library of code notebooks that our users – those interested in applying text analytics to research – can learn from and build upon. As the curators of such a resource, we need to learn from what’s been created before for a similar audience; and we need to understand how collections of notebooks can be used as an accessible resource for teaching, critiquing, and creating research using text analytics. These posts therefore summarise the insights we gained from a preliminary survey of key notebook resources.</p>
<p>This first part provides an introductory overview of the use of notebooks in text analytics and examines the pedagogically focussed genres of textbooks and tutorials. The second part looks at two other genres, tool chests and research articles, and ends with a summary and a consideration of how the discussion can inform the design of ATAP.</p>
<h2 id="what-are-notebooks">What are notebooks?</h2>
<p>Notebooks as popularised by the <a href="https://jupyter.org/" target="_blank" rel="noopener noreffer ">Jupyter project</a> have become a key medium for experimentation and presentation in research and development. They mix code with narrative text, as well as tables, figures and interactive tools generated by the code.</p>
<data id="id-1" data-raw></data>
<p>Figure 1 shows part of a notebook with some text, a code cell and the results generated by running the code</p>
<p>A notebook can be played with interactively, allowing a user to interrogate and tweak the analysis and datasets under construction; but it can also be run as a prefabricated script that fetches a dataset, applies some processing, or generates a report. For researchers, published notebooks provide an opportunity for experimental reproducibility and reusable research pipelines.</p>
<p>Notebooks collected together become a library of tutorials, tools, or reproducible research publications. We found several such collections covering applied text analytics, primarily targeting humanities and social sciences (HASS) researchers, as well as some resources that mix code and narrative, but in which the code cannot be executed directly. To make full use of such resources, it is necessary to copy the code and paste it into a console or another environment where it can be run.</p>
<p>In addition to having a mix of content, and different approaches to teaching or guiding readers to use text analytics tools, we noted a few broad genres of notebook and types of collection, such as tutorials, tool(kits), apps and research experiments, In this post, we focus on tutorials; the following post will look at the remaining genres..
Before going on, we’d like to note that our survey is by no means complete. We’ve not had time to look in detail at the full diversity of relevant notebook collections, but hope that we have captured useful insights about the state of the art.</p>
<h2 id="courses-for-different-horses">Courses for different horses</h2>
<p>While the various resources all covered core applied text analytics concepts – including acquiring data from various sources, analysing n-gram frequencies, extracting named entities, building and evaluating a topic model, and so on – notebook resources reflected different genres and hence user needs. Some sought to present a rigorous curriculum constructed of tutorials or lessons, others treat collections of notebooks as tools for the user to employ in their work, and others demonstrate the use of a notebook as a single-purpose reproducible research article.</p>
<h3 id="courses-and-textbooks">Courses and Textbooks</h3>
<p>The vast majority of notebook collections we identified positioned themselves as courses, with each notebook corresponding to a tutorial. Some tutorials provide scaffolding for exercises (with or without solutions), but at a baseline, they guide readers/users through the use of a tool or concept. Frequently, the intention is for these tutorial notebooks to be walked through in a workshop, but being openly published as notebooks allows users to execute and play with them outside of the classroom.</p>
<p><data id="id-2" data-raw></data>
Tutorials from different authors vary in how much they surround their code with narrative and background explanations of the techniques they are applying. Sinclair and Rockwell’s <a href="https://github.com/sgsinclair/alta/blob/master/ipynb/ArtOfLiteraryTextAnalysis.ipynb" target="_blank" rel="noopener noreffer ">The Art of Literary Text Analysis</a> (ALTA) provides extensive narrative and appears more like a textbook than a course, not intended for delivery, but for learning and reference. Melanie Walsh’s <a href="https://melaniewalsh.github.io/Intro-Cultural-Analytics/05-Text-Analysis/04-Sentiment-Analysis.html" target="_blank" rel="noopener noreffer ">Introduction to Cultural Analytics &amp; Python</a> explicitly presents itself as a text book constituted of notebooks, relying on the <a href="https://jupyterbook.org/intro.html" target="_blank" rel="noopener noreffer ">Jupyterbook</a> tool to give a glossy, accessible presentation, while also supporting the user to interact with the notebooks. Not unlike ALTA, this course demonstrates a deep appreciation of the breadth of technologies available and how they might be applied – and where they might not be applicable or reliable – in digital humanities contexts. It often supports the learner by giving multiple examples of how to apply a technique, which incidentally means repeated opportunities to demonstrate data preparation with diverse inputs.</p>
<p>For the R programming community, Martin Schweinberger’s <a href="https://slcladal.github.io/" target="_blank" rel="noopener noreffer ">LADAL</a> shows a thoroughness in developing users’ abilities from statistical basics to a breadth of NLP, corpus and computational linguistic methods. (As part of the ATAP project, LADAL tutorials are undergoing conversion from R markdown to Jupyter notebooks.) Technique-oriented introductory tutorials are then complemented with “focus studies” on disciplines of linguistic analysis such as learner language, stylistics or linguistic typology.
In comparison to the above sites, several other tutorial resources are much more bare, simply demonstrating how to implement a technique with little use of discussion or repeated examples.
The varying levels of narrative, and how they present the code, suggests that authors have a mix of goals that we might query:</p>
<ul>
<li>Is the tutorial introducing a technique, or rather its use through code?</li>
<li>Is it teaching the application of a technique, or how it works?</li>
<li>Does it aim to teach the reader how to read the code? How to experiment with the code? How to compose that code themselves?</li>
<li>Does the notebook itself facilitate those engagements with code, or does the more ephemeral teacher?</li>
</ul>
<p>Although not recently updated, we are indebted to Quinn Dombrowski’s curation of a <a href="https://github.com/quinnanya/dh-jupyter#course-materials" target="_blank" rel="noopener noreffer ">list of relevant courses and tutorials</a>, among other digital humanities notebooks. A recent player in this space is <a href="https://labs.jstor.org/tapi/" target="_blank" rel="noopener noreffer ">TAPI (Text Analysis Pedagogy Institute)</a>, which places open publication of notebook-based courses at the core of their researcher schooling. TAPI incorporates several courses by individual presenters, although there does not currently appear to be a high level of standardisation among the TAPI courses, including in their licensing.
<a href="https://programminghistorian.org/" target="_blank" rel="noopener noreffer ">The Programming Historian</a> is also an excellent resource for peer-reviewed digital humanities tutorials, often helpfully grounded in use cases. Not being notebooks (nor R markdown), its tutorials can’t be directly executed, leaving the user to copy-paste its code or not engage interactively with its content. What sets the Programming Historian apart is its design as a journal of tutorials, i.e. a collaborative enterprise in text analytics pedagogy. While resources we surveyed are all essentially open to third party contributors who may offer amendments, most collections of tutorial notebooks have single or few authors and are not designed as primarily collaborative endeavours.</p>
<p><a href="/posts/notebooks-2" rel="">Part 2</a> of this post looks at the remaining genres we have identified, libraries and tool chests and presentations of research results. Part 2 also includes a discussion of how the information collected here might shape our view of what ATAP can be.</p>
<p>Note 1: Unfortunately, we confined our survey to English-language resources; and with a focus on the Notebook medium, our analysis is biassed to (but not exclusively) the Python programming language.</p>
]]></description></item><item><title>Textbooks, tutorials and tool chests: different ways to learn from notebooks - Part 2</title><link>https://www.atap.edu.au/posts/notebooks-2/</link><pubDate>Wed, 27 Jul 2022 16:20:35 +1000</pubDate><author>Joel Nothman</author><guid>https://www.atap.edu.au/posts/notebooks-2/</guid><description><![CDATA[<h3 id="more-genres-of-notebooks-and-what-it-all-means-for-atap">More genres of notebooks and what it all means for ATAP</h3>
<h5 id="this-work-was-supported-by-the-sydney-informatics-hubhttpswwwsydneyeduauresearchfacilitiessydney-informatics-hubhtml-a-core-research-facility-of-the-university-of-sydney">This work was supported by the <a href="https://www.sydney.edu.au/research/facilities/sydney-informatics-hub.html" target="_blank" rel="noopener noreffer ">Sydney Informatics Hub</a>, a Core Research Facility of the University of Sydney</h5>
<p><a href="/posts/notebooks-1" rel="">Part 1</a> of this post introduced notebooks in general and identified various broad genres of notebook which have been used in providing text analytic tools. That part looked at notebooks as tutorials and the grouping of such materials into courses or textbooks. In this part, we look at notebooks which introduce individual tools and notebooks which present research results. The post ends with a consideration of how our analysis of different genres of notebook might influence the design of ATAP.</p>
<h3 id="libraries-and-tool-chests">Libraries and tool chests</h3>
<p>A “course” comes with a sense of order and completeness; a “tutorial” with a sense of guidance and demonstration. Some notebook collections appear more designed for reference or application than teaching, as if each notebook was a tool you could take from a chest and utilise for your needs.</p>
<p><data id="id-1" data-raw></data>
A notable collection in this space is Tim Sherratt’s <a href="https://glam-workbench.net/" target="_blank" rel="noopener noreffer ">GLAM Workbench</a>. Tim often titles a directory of notebooks as “tools, tips and examples”, which nicely summarises the mix of content that users can retrieve from the Workbench. “Tools” might include a <a href="https://nbviewer.org/github/GLAM-Workbench/australian-commonwealth-hansard/blob/master/Harvesting-Commonwealth-Hansard.ipynb" target="_blank" rel="noopener noreffer ">notebook for acquiring Australian parliament’s Hansard transcripts</a>, offering parameters that the user might change for their own project; or an <a href="https://github.com/GLAM-Workbench/trove-newspapers/blob/master/querypic.ipynb" target="_blank" rel="noopener noreffer ">app that summarises query results</a> from the National Library of Australia’s <a href="https://trove.nla.gov.au/" target="_blank" rel="noopener noreffer ">Trove</a>. An app, here, is distinguished by providing interactive widgets within a notebook, rather than expecting the user to set parameters in code and hit “run”. “Examples” includes a <a href="https://nbviewer.org/github/GLAM-Workbench/ozglam-workbench-naa-wap/blob/master/RecordSearch/2.%20Analyse%20a%20series.ipynb" target="_blank" rel="noopener noreffer ">case study</a> of filtering a corpus by its metadata, while a <a href="https://github.com/GLAM-Workbench/trove-newspapers/blob/master/find-non-english-newspapers.ipynb" target="_blank" rel="noopener noreffer ">walkthrough on language detection</a> applied to Trove incorporates many “tips” which help to identify the author’s thinking as his code takes each turn. Case studies like these lie on a spectrum between the genericity of tutorials often applied to demonstration or toy data, and the hypothesis-driven specificity of a research article. Grounding a topic in research use cases may help to evoke a sense of relevance to the user.
<data id="id-2" data-raw></data>
Notebooks presented as reusable tools may also be very similar to tutorials. Until recently, Ithaka’s <a href="https://constellate.org/" target="_blank" rel="noopener noreffer ">Constellate.org</a> – a core part of TAPI – included tutorial notebooks, and corresponding editions of the same notebook “for research”. (Here’s a <a href="https://github.com/ithaka/tdm-notebooks/blob/ea3c48e0094303a7d40dec4890c6cfdca275d22b/finding-significant-terms.ipynb" target="_blank" rel="noopener noreffer ">tutorial</a> and <a href="https://github.com/ithaka/tdm-notebooks/blob/ea3c48e0094303a7d40dec4890c6cfdca275d22b/finding-significant-terms-for-research.ipynb" target="_blank" rel="noopener noreffer ">research</a> pair on finding key terms in a corpus.) Each “research” notebook omits some of the guidance included in the tutorial, and was rather intended to be applied to a user-supplied dataset. The removal of these applied notebooks notwithstanding, it appears that the Constellate tutorials should dually function as reusable tools. The Constellate platform allows the user to create a corpus from JSTOR content, and select a tutorial/tool notebook from their collection, which is then applied to the new corpus. An important usability feature of reusable tools, and tutorials with this capability, is how they guide or support the user to apply the notebook to their own data.</p>
<p>Although targeting experienced corporate data scientists, rather than HASS researchers, data infrastructure provider Databricks openly publishes another relevant tool chest of notebooks (albeit not designed for the Jupyter platform). Their <a href="https://databricks.com/solutions/accelerators" target="_blank" rel="noopener noreffer ">Solution Accelerators</a> are designed to support a fairly code-savvy analyst in tackling standard data science problems in industry. (Read “Solution Accelerator” as a less patronising, more businessy, revamp of the term “starter kit”.) A Solution Accelerator notebook mixes narrative and code, inviting the user to bring their own data. It may give them data transformation code, models to apply, questions to ask, and diagnostics to perform. The library of Solution Accelerators shows how even a capable user may appreciate a notebook as a launchpad when working with new techniques. The apparent value of Solution Accelerators to Databricks customers highlights the risk and cost of undertaking analysis without workflow guidance from a notebook.</p>
<p>Unlike tutorials, a notebook tool chest does not make great efforts to build up a user’s skills from scratch, but supports them in selecting a tool that might be appropriate, seeing its relevance, and applying it to their needs.</p>
<h3 id="journals-and-anthologies">Journals and Anthologies</h3>
<p>Through their mix of code, narrative and generated tables and figures, notebooks are a powerful tool for presenting reproducible experimental results. A research paper implemented as a notebook may be rebuilt from its code, reproducing tables, figures and examples as the researcher modifies it. An article-as-notebook is distinguished by its focus on a specific research question, and application of whichever tools are appropriate to draw reliable conclusions. Although individual humanities researchers using digital methods might publish their research as code notebooks (see Quinn Dombrowski’s <a href="https://github.com/quinnanya/dh-jupyter#research--projects" target="_blank" rel="noopener noreffer ">list</a> for instance), institutional or discipline-specific collections of research notebooks are not yet common in applied text analysis and HASS. For comparison, a move towards reproducibility in other sciences allows one to find a multitude of research notebooks in venues like <a href="https://paperswithcode.com/" target="_blank" rel="noopener noreffer ">paperswithcode.com</a> and <a href="https://codeocean.com/explore/capsules" target="_blank" rel="noopener noreffer ">Code Ocean</a>.
<data id="id-3" data-raw></data>
When driven by a research question, the notebook author is less interested in demonstrating what techniques are <em>available</em> to apply, and more selective in using techniques that may helpfully harness their data towards a specific goal or narrative. The research thesis thus provides a way to specifically evaluate the output of an analysis: does it support a hypothesis? does it induce a new hypothesis? does it suggest problems in the modelling? The final research notebook may hide aspects of this iterative experimentation, evaluation, and the response of further investigation, issue mitigation, or discarding a path of investigation. (The ideal reproducible research notebook would keep track of dead ends too!)
Tutorials and tools may emulate these processes of iterative development, or provide a range of possible pathways for analysis; the research notebook, however, must keep its focus on the thesis being explored.</p>
<p>The <a href="https://journalofdigitalhistory.org/" target="_blank" rel="noopener noreffer ">Journal of Digital History</a> is a new player in this space, releasing its first issue in October 2021. This project of the Luxembourg Centre for Contemporary and Digital History and De Gruyter ensures some reproducibility by requiring the code which constructs the research article to be executable and its data available to reproduce tables and figures, while allowing the reader to evaluate and reuse the research implementation. It goes further in harnessing the notebook medium to add layers of depth to peer-reviewed publications in digital history: viewing a JDH publication, a reader is able to hide what they call the “hermeneutic layer” of the work, which provides methodological detail, as distinct from the narrative arc of the research. The notebook medium applied in this way is able to shift several paradigms about how research is constructed, presented, and accessed.</p>
<h3 id="bringing-it-back-to-users">Bringing it back to users</h3>
<p>In positioning the Australian Text Analytics Platform’s role amidst ongoing and past resource creation, we have to consider how our library of notebooks might build outcomes for our users. Here are some outcomes we are considering.</p>
<h4 id="reference-and-application">Reference and Application</h4>
<ul>
<li>User has access to starters’ kits for a wide range of techniques, covering data modelling, validation and analysis, archiving, etc.</li>
<li>User can experiment with standard tools applied to demo data or their own.</li>
<li>User can adapt code notebooks to their own use cases.</li>
<li>User is able to compare alternative methods for similar goals.</li>
</ul>
<h4 id="growth-and-learning">Growth and Learning</h4>
<ul>
<li>User is familiar with what selected research methods look like as code.</li>
<li>User is familiar with what end-to-end research looks like as code.</li>
<li>User can prepare their own data for existing or standard tools.</li>
<li>User understands how their research problem might translate to a computational problem, and the applicable techniques.</li>
<li>User is able to combine multiple techniques to achieve their research goals.</li>
<li>User understands how to build good research software.</li>
<li>User can confidently build a notebook from scratch for their own research.</li>
</ul>
<p>We also need to define who our user personas are: is it someone with academic expertise, but little in code? or someone with moderate code literacy, but stuck with how to create notebooks for reproducible research? The latter might be more interested in published starter kits, case studies and experiments, while the former needs the guidance provided by a tutorial.</p>
<h3 id="where-to-from-here">Where to from here?</h3>
<p>By surveying several collections of notebooks for text analytics, we have a stronger understanding of the spectrum of materials ATAP’s library can incorporate, both in content and in genre.</p>
<p>One apparent opportunity is to curate or improve a catalogue of existing resources that will meet the needs of the Australian text analytics research community. It’s also possible to see areas where existing resources may fail to meet the needs of current users of desktop and web tools for corpus analysis from <a href="https://voyant-tools.org/" target="_blank" rel="noopener noreffer ">Voyant Tools</a> to <a href="https://www.laurenceanthony.net/software/antconc/" target="_blank" rel="noopener noreffer ">AntConc</a>; those tools provide interactivity that carries the user across views of statistics, query matches and texts, but tend to be limited in facilitated reproducible research and in extensibility to arbitrary corpus cleaning and analysis procedures. Tying the resources we’ve looked at to user outcomes also gives a better understanding how to evaluate accessibility of a notebook and the learning opportunities arising from it, such as to what extent a resource:</p>
<ul>
<li>supports the user getting their own data into the notebook.</li>
<li>demonstrates the combination of multiple techniques into research.</li>
<li>helps a researcher choose techniques relevant to their research question.</li>
<li>supports the user to experiment with the code of the notebook</li>
<li>demonstrates the processes and challenges around using/applying a technique and the code needed to implement those decisions e.g. decisions to make before and after applying topic models.</li>
</ul>
<p>Overall, we’ve talked little about how notebooks present their content, and how that presentation might affect user engagement and the sustainability of the resource. Of course, those concerns are also important in looking at principles for quality in notebook resources for digital humanities and other text analytics users.</p>
]]></description></item><item><title>What are the FAIR and CARE principles and why should corpus linguists know about them?</title><link>https://www.atap.edu.au/posts/fair-and-care/</link><pubDate>Tue, 08 Feb 2022 15:28:35 +1000</pubDate><author>Simon Musgrave</author><guid>https://www.atap.edu.au/posts/fair-and-care/</guid><description><![CDATA[<h1 id="fair-and-care">FAIR and CARE</h1>
<p>Data is becoming increasingly important in today’s world, so corpus linguists might feel that the rest of the world is finally catching up. But the rest of the world are bringing with them new approaches to how data is handled. This means that fields such as corpus linguistics may need to reassess their practices. Such reassessment includes addressing concerns about how data is stored and who can access it (data stewardship) – concerns that are a part of the <a href="https://en.wikipedia.org/wiki/Open_science" target="_blank" rel="noopener noreffer ">Open Science</a> movement, ultimately grounded on principles of equity and accountability.</p>
<p>The most influential approach to data stewardship today is the <a href="https://www.go-fair.org/" target="_blank" rel="noopener noreffer ">FAIR</a> principles.
According to these principles, data should be:</p>
<ul>
<li>
<p><em>Findable</em></p>
<p>  Metadata and data should be easy to find for both humans and computers.</p>
</li>
<li>
<p><em>Accessible</em></p>
<p>  Once the user finds the required data, she/he/they need to know how can they be accessed, possibly including authentication and authorisation.</p>
</li>
<li>
<p><em>Interoperable</em></p>
<p>  The data usually need to be integrated with other data. In addition, the data need to interoperate with applications or workflows for analysis, storage, and processing.</p>
</li>
<li>
<p><em>Reusable</em></p>
<p>  The ultimate goal of FAIR is to optimise the reuse of data. To achieve this, metadata and data should be well-described so that they can be replicated and/or combined in different settings.</p>
</li>
</ul>
<p>In general, corpus linguists do well on the interoperability criterion. Corpus data is usually stored in non-proprietary formats; even when some structure is imposed on the data, this is almost always in a form which is saved as a simple text file (e.g. csv files or xml annotations). Data stored in such formats is easy to move between applications. But what about the other three criteria?</p>
<p>Some corpus data is easy to discover; it is findable. For example CLARIN, the <a href="https://www.clarin.eu/content/data" target="_blank" rel="noopener noreffer ">portal</a> to the European Union language resource infrastructure, provides access to many large data collections, as does the <a href="https://www.ldc.upenn.edu/" target="_blank" rel="noopener noreffer ">Linguistic Data Consortium</a> in the USA. However, some data is never made part of a large collection and often remains under the control of individual researchers or research teams. Such data may be almost impossible to find. Even if we can find such data, it is unlikely to be accompanied by good descriptions of the data and metadata, making reusability problematic. Of course, big corpora such as the <a href="http://www.natcorp.ox.ac.uk/" target="_blank" rel="noopener noreffer ">British National Corpus</a> will be both findable and accompanied by comprehensive corpus manuals. However, it is worth considering how to make other corpora more findable, including the provision of corpus manuals or corpus descriptions. Corpus resource databases such as <a href="https://varieng.helsinki.fi/CoRD/" target="_blank" rel="noopener noreffer ">CoRD</a> do aim to work towards this principle.</p>
<p>Accessibility may also be an issue for some data. Copyright law may allow use of material for individual research but prohibit any further distribution of the material. The FAIR approach to such cases is that metadata should be available so that interested parties can know that a data holding exists (F), and the metadata will include information about the conditions under which the data may or may not be shared or reused (A and R).</p>
<data id="id-1" data-raw></data>
<p>For linguists, there is another very important set of principles concerning data, the CARE principles developed by the Global Indigenous Data Alliance:</p>
<ul>
<li>
<p><em>Collective Benefit</em></p>
<p>  Data ecosystems shall be designed and function in ways that enable Indigenous Peoples to derive benefit from the data.</p>
</li>
<li>
<p><em>Authority to control</em></p>
<p> Indigenous Peoples’ rights and interests in Indigenous data must be recognised and their authority to control such data be empowered.</p>
</li>
<li>
<p><em>Responsibility</em></p>
<p> Those working with Indigenous data have a responsibility to share how those data are used to support Indigenous Peoples’ self-determination and collective benefit.</p>
</li>
<li>
<p><em>Ethics</em></p>
<p> Indigenous Peoples’ rights and wellbeing should be the primary concern at all stages of the data life cycle and across the data ecosystem.</p>
</li>
</ul>
<p>These principles are presented as applying particularly to Indigenous data, but we believe that researchers should adopt this approach in all cases where the people who participate in our research can be seen to have some moral rights in the information they have contributed. Respecting those moral rights should be demonstrated by recognising the participants’ authority to control how data is used, by seeking to ensure that participants derive benefit from use of the data, and by acting ethically and transparently in our relations with the participants. Deborah Cameron and her colleagues (Cameron et al 1993) raised similar issues almost 20 years ago, arguing that the imbalance of power in the relation between researchers and participants needed to be reduced. The CARE principles continue along this path, but go even further in explicitly returning power to the sources of information.</p>
<p>Corpus data is often written language. We have already mentioned that copyright law is relevant to some such material, and that body of law protects at least some rights for the creators of the material. But corpus linguists also work with other kinds of data such as spoken language (spontaneous or produced as a response to some prompt) or written material produced by research participants according to some protocol. In such cases, ethical research practice should include addressing the issues raised by the CARE principles. Some aspects of this practice will fall under institutional ethics requirements (for example, thinking carefully about what permissions we request on consent forms), but other questions must be part of the relationship between the researcher and the research participants. Corpus linguists working with spoken, computer-mediated, or otherwise particularly sensitive data have been aware of at least some of these issues, but the CARE principles offer an opportunity to go further.</p>
<p>Acquiring data for linguistic research takes effort and often that means money. It is therefore a good use of resources if any data we collect can be used by others. The FAIR principles provide a framework to make sharing and reusing data easier, and applying the CARE principles where relevant helps to ensure that our research has a sound ethical basis.</p>
<p>Note: This post is based on the presentation ‘Advance Australia FAIR’, given by Simon Musgrave and Michael Haugh to the 4th Forum on Englishes in Australia (LaTrobe University, August 27, 2021).</p>
<p>Thanks to Leah Gustafson and Monika Bednarek for helpful comments on drafts.</p>
<p><strong>Reference:</strong>
<data id="id-2" data-raw></data></p>
]]></description></item></channel></rss>